{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install langchain openai tiktoken chromadb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('./data/', glob=\"./*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "## Here is the nmew embeddings being use\n",
    "embedding = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "                                          model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = vectordb.as_retriever()\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "# retriever.search_type\n",
    "# retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"과거는 반복된다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='인 차원으로 풀이되어 옴에 따라 읍면동과 같은 소지역 단위에서의 빈집정비 방향\\n설정에 유효한 설명이 부족하였음. 이상의 분석결과는 같은 지자체 안에서도 빈집\\n발생 정도에 차이가 나타나는 이유를 설명하는 틀을 제공하며, 빈집 발생을 완화하\\n기 위해 취할 수 있는 정책적 방안 모색을 가능케 함\\n  ◦ 빈집 발생 및 증가 현상에 대한 이해 증대\\n   - 분석결과 읍면동 내 빈집 발생 및 증가 현상은 인구구조 특성뿐만 아니라 지역의\\n경제적 상황, 생활편의 등 지역생태학적 요인이 복합적으로 작용한 결과임. 단순히\\n중앙 및 지방자치단체기관이 지방으로 이전되었다고 해서 빈집 발생이 억제되는 효\\n과로 이어지지 않으며, 분석결과에서도 자치단체기관수가 빈집 발생에 유의한 영향\\n을 미치지 않는 것으로 나타남. 또한 도시 지역의 빈집 발생은 폐업 사업체수 등\\n지역의 경제적 상황과 밀접히 관련되어 있다는 분석결과는 최근 대기업 두 곳이 연\\n이어 철수한 군산 등 전북 지역의 빈집 발생 심화현상에 적확한 설명을 제공함', metadata={'source': 'data/지역의 사회구조적 특성이 빈집 형성에 미친 영향에 관한 패널 분석(우수).pdf', 'file_path': 'data/지역의 사회구조적 특성이 빈집 형성에 미친 영향에 관한 패널 분석(우수).pdf', 'page': 4, 'total_pages': 6, 'format': 'PDF 1.4', 'title': '', 'author': 'mhan', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20200724181319+09'00'\", 'modDate': \"D:20200724181319+09'00'\", 'trapped': ''}),\n",
       " Document(page_content='일수록 유의하게 빈집이 증가하는 것은 신림동 노량진 등 전통적인 고시촌이 쇠락\\n하고 있는 상황을 반영하는 것으로 보임. 한편, 빈집 발생 및 증가 현상은 연도별로\\n심화되고 있음\\n3. 분석 결과 활용\\n 1) 현황분석을 통한 시사점 / 정책 제안 / 창업 아이디어의 핵심내용 (독창성･차별성)\\n  ◦ 지역 내 빈집 발생을 완화하기 위한 방안\\n   (1) [여성가구주가 정주할 수 있는 여건 조성] 동부 및 읍면부 공히 여성가구주수가\\n증가할수록 빈집이 감소하는 것으로 나타남. 이는 여성가구주가 안심하고 정주할\\n수 있는 여건(예컨대 야간 보행안전 확보, 도로변 쓰레기 치우기 등 환경미화)이\\n갖춰진 지역에서는 빈집이 발생할 가능성이 낮아짐을 시사함\\n   (2) [취약주택 및 노후주택의 정비] 비닐하우스 등 취약주택수가 많을수록, 평균 건축\\n연도가 오래되었을수록, 20년 이상 노후주택이 많을수록, 읍면동 내 빈집 증가에\\n유의한 영향을 미침. 이러한 맥락에서 낙후된 주택의 외관을 정비하는 지자체의\\n도시재생 사업은 빈집 감소에 긍정적인 효과를 기대할 수 있음. 다만 빈집 감소를\\n목적으로 하는 도시재생 사업은 지역의 주택 상황과 빈집 발생간의 연관성이 낮\\n은 농촌(읍면부) 단위에서는 유의하지 못함\\n   (3) [신중한 신축주택 건설] 5년 미만 신축주택수의 증가는 빈집 증가와 관련 있는 요\\n인으로 확인됨. 거시적으로 인구가 감소하고 빈집이 증가하고 있는 상황을 고려할\\n때 소지역 단위에서도 신축주택 건설에 보다 신중을 기할 필요가 있음', metadata={'source': 'data/지역의 사회구조적 특성이 빈집 형성에 미친 영향에 관한 패널 분석(우수).pdf', 'file_path': 'data/지역의 사회구조적 특성이 빈집 형성에 미친 영향에 관한 패널 분석(우수).pdf', 'page': 3, 'total_pages': 6, 'format': 'PDF 1.4', 'title': '', 'author': 'mhan', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20200724181319+09'00'\", 'modDate': \"D:20200724181319+09'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Chin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    # print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "사회구조적 특성이 빈집 형성에 끼친 영향은 다양합니다. 예를 들어, 사회구조가 공동체 중심적이라면, 가구가 생기거나 사람들이 이사하는 경우 빈집이 생기기가 쉽습니다. 반면, 사회구조가 개인 중심적이라면, 빈집이\n",
      "\n",
      "\n",
      "Sources:\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"사회구조적 특성이 빈집 형성에 끼친 영항에 대해 설명해주세요\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleteing the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# delete the directory\n",
    "!rm -rf db/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting again loading the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding,\n",
    "                   )\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
