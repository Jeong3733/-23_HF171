{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str='cl100k_base') -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "# loader = DirectoryLoader('./data/', glob=\"./*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "file_path='data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf'\n",
    "loader = PyMuPDFLoader(file_path=file_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "persist_directory = 'doc_db'\n",
    "\n",
    "doc_vectordb = Chroma.from_documents(documents=docs, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectordb.persist()\n",
    "doc_vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = doc_vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표절검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'total_db'\n",
    "\n",
    "total_vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(query):\n",
    "    return doc_vectordb.similarity_search_with_score(query=query, distance_metric=\"cos\", k = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='서울특별시 버스 노선 혼잡도 예측을 통한 다람쥐버스 신규 노선 \\n제안\\n1. 주제 선정 및 자료분석 배경 (주제 선정의 독창성) \\n을지로, 여의도 같은 기업의 밀집도가 높은 지역들의 출퇴근 시간에는 대중교통, 자가용 할 것 없이 모\\n든 이동수단의 포화상태를 볼 수 있다. 출퇴근 시간에서의 교통 혼잡도를 줄이기 위해서 대중교통의 이\\n용을 적극 홍보하고 있지만, 사실상 버스와 지하철을 타지 못하고 몇 대씩 보내고 난 다음에야 탑승할 \\n수 있을 정도로 이용객이 넘쳐난다. 이러한 문제를 해결하기 위해 서울시에서 다람쥐버스의 운행을 시\\n작하였다. 다람쥐버스는 서울시에서 운행하는 출퇴근 맞춤버스로 출퇴근 시간대의 특정 구간에서 발생\\n하는 차내 혼잡을 해소하기 위해 운행하는 순환형 셔틀버스이다. 다람쥐버스라는 이름은 다람쥐가 쳇바\\n퀴 돌듯 짧은 구간을 반복 운행한다고 하여 붙여졌다.\\n2017년 6월에 4개의 노선으로 반년 간의 시범 운행을 한 결과 차내 혼잡을 39.5% 완화하는 효과와 동\\n시에 해당 구간의 전체 버스 이용객이 16.5% 증가하는 효과를 볼 수 있었다. 이러한 결과를 반영하여 \\n2018년에는 3개의 노선이 추가되어 현재는 총 7개의 노선이 운행 중이다.\\n다람쥐버스는 현재 이미 시행 중인 정책이지만 2018년에 국토교통부가 주관한 2018 지속가능 교통도시\\n평가에서 최우수정책으로 선정될 만큼 긍정적인 평가를 받고 있고 타 지역에서의 운행을 기대하는 시민\\n들의 목소리도 높은 것으로 나타났다. 따라서 이번 과제에서 버스 정류소 및 노선별 이용객 수를 예측\\n하고 버스 내 혼잡도를 계산함으로써 가장 큰 효과를 얻을 수 있는 신규 노선을 제안하고자 한다. \\n2. 분석 내용 (자료분석의 우수성, 데이터 활용성)\\n활용데이터\\n『서울시 버스노선별, 정류장별, 시간대별 승·하차 인원 정보』 데이터에서 일별, 시간대별 승·하차 인원을 \\n구하기 위해 출근 시간대인  7시~9시의 승·하차 인원을 추출, 평균을 취하고 연도별 일수로 나누었다.', metadata={'source': 'data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf', 'file_path': 'data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf', 'page': 0, 'total_pages': 5, 'format': 'PDF 1.4', 'title': '', 'author': 'user', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20200724181854+09'00'\", 'modDate': \"D:20200724181854+09'00'\", 'trapped': ''}),\n",
       "  0.500114381313324),\n",
       " (Document(page_content='2. 분석 내용 (자료분석의 우수성, 데이터 활용성)\\n활용데이터\\n『서울시 버스노선별, 정류장별, 시간대별 승·하차 인원 정보』 데이터에서 일별, 시간대별 승·하차 인원을 \\n구하기 위해 출근 시간대인  7시~9시의 승·하차 인원을 추출, 평균을 취하고 연도별 일수로 나누었다. \\n『stationList』, 『busStationbyRouteList』에서 얻은 버스정류장의 위·경도를 위에서 만든 버스 데이터에 \\n합치고, (승차 인원 – 하차 인원)/(60 / 배차간격) 식을 이용하여 버스 한 대별 순승차인원을 구하고, \\n(버스 별 누적 탑승인원 / 60) * 100 식으로 혼잡도지표를 생성하였다. 지역별 인구정보를 활용하기 \\n위해 Python의 selenium을 이용하여 정류소별 행정동 주소를 네이버 지도에서 크롤링하고, 이 주소와 \\n『서울시 동별 사업체 및 종사자 밀도 통계』 이용하여 행정동별 총 인구수, 사업체 수, 종사자 수 \\n데이터를 합쳤다. 정류소번호의 위·경도 데이터와 『구/동 별 주거 지역, 상업지역』, 『학교 정보』 \\n데이터를 이용하여 반경 500m 내 상업지구, 주거지구 수와 중·고·대학교·대학원 수, 그 학교에 다니는 \\n학생(재적학생) 수, 교사(교수) 수를 합쳤다. 또한 『지하철 역별 시간대별 승·하차 인원수』 데이터를 \\n이용하여 가장 가까운 지하철역의 출근 시간대 평균 승, 하차 정보와 해당 지하철역을 다니는 호선 \\n수를 합쳤다. 마지막으로 통계빅데이터센터 『기초정보_인구집중유발시설』 데이터에서 대형유통점, \\n백화점, 숙박시설의 자료만을 추출하여 버스정류장의 반경 500m 내에 있는 시설의 수를 추가하였다.\\nMODELING\\n모델링을 하기에 앞서 기준을 세우기 위해 다음과 같이 설명변수를 전혀 넣지 않은, 랜덤으로 순승차량\\n을 예측했을 때의 RMSE값을 구했다. 또한 y변수인 순승차량의 분포를 그래프로 나타냈다. \\n데이터명\\nSource\\n비고\\n서울시 버스노선별, 정류장별, \\n시간대별 승·하차 인원 정보\\n서울열린데이터광장\\n기본 데이터', metadata={'source': 'data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf', 'file_path': 'data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf', 'page': 0, 'total_pages': 5, 'format': 'PDF 1.4', 'title': '', 'author': 'user', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20200724181854+09'00'\", 'modDate': \"D:20200724181854+09'00'\", 'trapped': ''}),\n",
       "  0.5151349306106567),\n",
       " (Document(page_content='클러스터링\\n현재 운행 중인 다람쥐버스가 지나는 지역의 특성을 파악하기 위해 군집화 분석을 진행하였다. EM알고\\n리즘을 기반으로 한 군집분석을 시행한 결과 3개의 그룹으로 나누는 것이 가장 적절하다고 판단하였다. \\n그 결과 각 그룹은 아래 표와 같은 특성을 보였고 이를 서울시 지도에 다음과 같이 나타낼 수 있었다.\\n다람쥐 버스 추천\\n위에서 버스 정류장 주변에 있는 정보를 이용하여 해당 버스 정류장의 순 승차량을 예측하였다. 이제 \\n예측한 순 승차량을 이용하여 새로운 다람쥐 버스를 추천하고자 한다. 혼잡도 지표 식을 이용하여 계산\\n한 다음, 전체 혼잡도의 상위 5% 안에 있는 값들이 연속된 구간을 찾고 개수를 세었다. \\n연속 구간이 가장 많은 버스는 5616인데, 혼잡 구간이 현재 다람쥐버스 8552가 다니고 있기 때문에 제\\n외하였다. 650번 버스의 혼잡구간은 6625번 버스의 구간과 비슷했고, 333번 버스의 경우 혼잡구간이 상\\n업지역(class 1,2)에서 주거지역(class 3)으로 운행하는 경향이 있어 추천 목록에서 제외하였다. 다람쥐 버\\n스 노선 구간은 위의 노선버스에서 주거지역에서 상업지역으로 운행하는 구간을 차용하였다. 제안한 다\\n람쥐 버스의 정류소별 지역정보를 시각화하여 나타내면 다음과 같다.\\n146번 버스를 차용한 다람쥐버스 추천 노선 구간을 살펴보면, 기점쪽에는 주거비율, 종점 쪽에는 사업체 \\n및 종사자 수가 더 많음을 볼 수 있다. 6625번, 360번 버스도 마찬가지로 나타났다.\\n노선버스\\n5616\\n146\\n6625\\n650\\n333\\n360\\n연속구간\\n89\\n69\\n56\\n44\\n42\\n41\\nclass\\n학생수\\n사업체수\\n종사자수\\n총인구수\\n지하철\\n버스\\n상업지역\\n주거지역\\n편의시설\\n1(주거+\\n상업)\\n3695\\n2400\\n18131\\n27446\\n1.37\\n3.99\\n1.33\\n13.7\\n2.91\\n2(상업)\\n12129\\n5224\\n45720\\n21989\\n1.81\\n4.27\\n4.27\\n13.5\\n8.15\\n3(주거)\\n2373\\n1505\\n7099\\n27035\\n1\\n2.67\\n2.67\\n13.8\\n1.48', metadata={'source': 'data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf', 'file_path': 'data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf', 'page': 2, 'total_pages': 5, 'format': 'PDF 1.4', 'title': '', 'author': 'user', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20200724181854+09'00'\", 'modDate': \"D:20200724181854+09'00'\", 'trapped': ''}),\n",
       "  0.5211096405982971),\n",
       " (Document(page_content='람쥐 버스를 신규 노선으로 제안할 수 있을 것이다. \\n3. 분석 결과 활용\\n현재 출퇴근 시간에서의 교통 혼잡도는 매우 높으며 대중교통의 이용 또한 이미 포화상태이다. 전체 대\\n중교통의 이용자 수는 늘리되, 차량 당 혼잡도를 줄이고자 일종의 셔틀 개념을 가진 다람쥐버스가 시행\\n되었으며, 이는 충분히 서울 내, 외 다양한 지역에서 적용이 가능하다. 버스의 이용객 수 예측이 적절히 \\n이루어진다면 최대 효과를 볼 수 있는 루트를 찾고 빠른 시행을 기대해볼 수 있다. 따라서 버스 정류소 \\n및 노선별 이용객 수를 예측하고, 이를 토대로 혼잡도 계산을 하여 신규 루트를 제안해보았다. \\n다람쥐버스는 다시 말하자면 이미 시행되고 있는 정책이다. 학생들의 등교 및 직장인들의 출근시간에 \\n맞춘 단거리 순환버스는 짧은 운행시간으로도 상당한 효과를 보여주고 있다. 이 프로젝트에서는 다양한 \\n변수들을 이용하여 기존의 버스 노선들의 정류장별 순승차인원(승차 – 하차)을 예측하였다. 모델링을 통\\n해 버스정류장 주변 지역 정보를 이용했기 때문에 객관적인 노선제안 방식이라고 말할 수 있다. 여기서 \\n얻은 승차 인원 예측 정보를 통해 배차 간격 및 운행시간을 알맞게 조정하여 시행할 수 있을 것이다.  \\n버스 정류장들을 군집화함으로써 신규 정류장이 건설되거나 기존의 것이 변경되었을 때 손쉽게 적절한 \\n분류가 가능하다는 것이다. 따라서 다람쥐 버스의 신규 노선을 추천하는 작업에서 일반화된 클러스터를 \\n이용할 수 있다는 장접을 가지고 있다. \\n버스 노선\\n기∙종점\\n대수\\n거리\\n배차간격\\n횟수\\n운행시간\\n8991\\n한국전력동부지사 ~ \\n한국무역센터.삼성역\\n5\\n12.3km\\n10~12 분\\n11\\n07:00~09:00\\n8881\\n강서초등학교 ~ \\nKT&G영등포지사.문래동종점\\n4\\n9.18km\\n10~11 분\\n12\\n07:00~09:00\\n8111\\n신길새마을금고 ~ \\n한국자산식탁.르네상스호텔\\n5\\n13.7km\\n10~12 분\\n11\\n17:30~19:30', metadata={'source': 'data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf', 'file_path': 'data/서울특별시 버스노선 혼잡도 예측을 통한 다람쥐버스 신규 노선제안(장려).pdf', 'page': 4, 'total_pages': 5, 'format': 'PDF 1.4', 'title': '', 'author': 'user', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20200724181854+09'00'\", 'modDate': \"D:20200724181854+09'00'\", 'trapped': ''}),\n",
       "  0.5246822237968445)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = sim('query')\n",
    "k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "resList = []\n",
    "for doc in docs:\n",
    "    for r in retriever.get_relevant_documents(doc.page_content):\n",
    "        resList.append((doc, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세 개의 역 따옴표를 구분된 텍스트 2개는 어떠한 부분에서 비슷하다고 유사하다고 할 수 있나요?\n",
      "    \n",
      "    ```서울특별시 버스 노선 혼잡도 예측을 ```\n",
      "    ```서울특별시 버스 노선 혼잡도 예측을 ```\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for original, why in resList[:1]:\n",
    "    # print(original.page_content[:20], why.page_content[:20])\n",
    "    o = original.page_content[:20]\n",
    "    w = why.page_content[:20]\n",
    "    prompt = f\"\"\"세 개의 역 따옴표를 구분된 텍스트 2개는 어떠한 부분에서 비슷하다고 유사하다고 할 수 있나요?\n",
    "    \n",
    "    ```{o}```\n",
    "    ```{w}```\n",
    "    \"\"\"\n",
    "    print(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"map_reduce\",\n",
    "                             verbose = False)\n",
    "\n",
    "output_summary = chain.run(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
